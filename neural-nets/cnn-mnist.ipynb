{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "X_valid_raw = mnist.validation.images\n",
    "y_valid = mnist.validation.labels\n",
    "X_test_raw = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_raw.reshape([X_train.shape[0], 28, 28, 1])\n",
    "X_valid = X_valid_raw.reshape([X_valid.shape[0], 28, 28, 1])\n",
    "X_test = X_test_raw.reshape([X_test.shape[0], 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, input_height, input_width, input_channels = X_train.shape\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, input_height, input_width, input_channels],\n",
    "                   dtype=tf.float32,\n",
    "                   name='X')\n",
    "y = tf.placeholder(shape=None, dtype=tf.int64, name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X,\n",
    "                        filters=32,\n",
    "                        kernel_size=5,\n",
    "                        strides=[1,1],\n",
    "                        padding=\"SAME\",\n",
    "                        name='conv1',\n",
    "                        activation=tf.nn.relu)\n",
    "pool1 = tf.nn.avg_pool(conv1,\n",
    "                       ksize=[1,2,2,1],\n",
    "                       strides=[1,2,2,1],\n",
    "                       padding=\"VALID\",\n",
    "                       name='pool1')\n",
    "conv2 = tf.layers.conv2d(X,\n",
    "                        filters=64,\n",
    "                        kernel_size=5,\n",
    "                        strides=[2,2],\n",
    "                        padding=\"SAME\",\n",
    "                        name='conv2',\n",
    "                        activation=tf.nn.relu)\n",
    "pool2 = tf.nn.avg_pool(conv2,\n",
    "                       ksize=[1,2,2,1],\n",
    "                       strides=[1,2,2,1],\n",
    "                       padding=\"VALID\",\n",
    "                       name='pool2')\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "dense1 = tf.layers.dense(pool2_flat, 100, activation=tf.nn.relu, name='dense1')\n",
    "dropout = tf.layers.dropout(inputs=dense1, rate=0.5)\n",
    "logits = tf.layers.dense(dropout, n_outputs, name='logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define individual cross entropy and overall loss for a batch\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                   beta1=0.9,\n",
    "                                   beta2=0.999)\n",
    "training_step = optimizer.minimize(loss, name='training_step')\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Train accuracy:', 0.98000002, 'Val accuracy:', 0.98220003)\n",
      "(1, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98320001)\n",
      "(2, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98180002)\n",
      "(3, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98320001)\n",
      "(4, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98439997)\n",
      "(5, 'Train accuracy:', 0.98000002, 'Val accuracy:', 0.98119998)\n",
      "(6, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98220003)\n",
      "(7, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98500001)\n",
      "(8, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98140001)\n",
      "(9, 'Train accuracy:', 0.98000002, 'Val accuracy:', 0.98460001)\n",
      "(10, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98720002)\n",
      "(11, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98379999)\n",
      "(12, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98379999)\n",
      "(13, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98619998)\n",
      "(14, 'Train accuracy:', 0.98000002, 'Val accuracy:', 0.98360002)\n",
      "(15, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98400003)\n",
      "(16, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98699999)\n",
      "(17, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98500001)\n",
      "(18, 'Train accuracy:', 0.98000002, 'Val accuracy:', 0.986)\n",
      "(19, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98460001)\n",
      "(20, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98320001)\n",
      "(21, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98479998)\n",
      "(22, 'Train accuracy:', 1.0, 'Val accuracy:', 0.986)\n",
      "(23, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98580003)\n",
      "(24, 'Train accuracy:', 0.98000002, 'Val accuracy:', 0.98559999)\n",
      "(25, 'Train accuracy:', 1.0, 'Val accuracy:', 0.986)\n",
      "(26, 'Train accuracy:', 1.0, 'Val accuracy:', 0.986)\n",
      "(27, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98540002)\n",
      "(28, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98479998)\n",
      "(29, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98619998)\n",
      "(30, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98460001)\n",
      "(31, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98400003)\n",
      "(32, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98479998)\n",
      "(33, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98540002)\n",
      "(34, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98680001)\n",
      "(35, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98619998)\n",
      "(36, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98640001)\n",
      "(37, 'Train accuracy:', 1.0, 'Val accuracy:', 0.9874)\n",
      "(38, 'Train accuracy:', 1.0, 'Val accuracy:', 0.98799998)\n",
      "(39, 'Train accuracy:', 1.0, 'Val accuracy:', 0.9878)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        rand_idx = np.random.permutation(np.arange(n_samples))\n",
    "        for iteration in range(n_samples // batch_size):\n",
    "            batch_idx = rand_idx[(iteration*batch_size):((iteration+1)*batch_size)]\n",
    "            X_batch = X_train[batch_idx,:]\n",
    "            y_batch = y_train[batch_idx]\n",
    "            sess.run(training_step, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid,\n",
    "                                           y: y_valid})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neural-nets]",
   "language": "python",
   "name": "conda-env-neural-nets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
